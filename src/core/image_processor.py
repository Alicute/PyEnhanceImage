"""
å›¾åƒå¤„ç†ç®—æ³•æ¨¡å—
"""
import numpy as np
from skimage import exposure, filters, morphology, restoration
from typing import Dict, Any, Tuple, Optional

# å¯¼å…¥æ–°çš„å¤„ç†å™¨æ¨¡å—
from .frequency_processor import FrequencyProcessor
from .edge_processor import EdgeProcessor
from .dicom_enhancer import DicomEnhancer
from .window_based_enhancer import WindowBasedEnhancer
from .paper_enhance import enhance_xray_poisson_nlm_strict

class ImageProcessor:
    """å›¾åƒå¤„ç†ç®—æ³•é›†åˆ"""
    
    @staticmethod
    def gamma_correction(data: np.ndarray, gamma: float = 1.0) -> np.ndarray:
        """Gammaæ ¡æ­£"""
        if gamma <= 0:
            gamma = 0.1
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        normalized = data.astype(np.float32)
        normalized = (normalized - normalized.min()) / (normalized.max() - normalized.min())
        
        # åº”ç”¨Gammaæ ¡æ­£
        corrected = np.power(normalized, gamma)
        
        # æ¢å¤åˆ°åŸå§‹èŒƒå›´
        corrected = corrected * (data.max() - data.min()) + data.min()
        
        return corrected.astype(np.uint16)
    
    @staticmethod
    def histogram_equalization(data: np.ndarray, method: str = 'global') -> np.ndarray:
        """ç›´æ–¹å›¾å‡è¡¡åŒ–"""
        if method == 'global':
            # å…¨å±€ç›´æ–¹å›¾å‡è¡¡åŒ–
            return exposure.equalize_hist(data) * 65535
        elif method == 'adaptive':
            # è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆCLAHEï¼‰
            return exposure.equalize_adapthist(data) * 65535
        else:
            return data
    
    @staticmethod
    def gaussian_filter(data: np.ndarray, sigma: float = 1.0) -> np.ndarray:
        """é«˜æ–¯æ»¤æ³¢"""
        if sigma <= 0:
            sigma = 0.1
        
        # è½¬æ¢ä¸ºfloatç±»å‹è¿›è¡Œå¤„ç†
        filtered = filters.gaussian(data.astype(np.float32), sigma=sigma)
        
        # æ¢å¤åˆ°åŸå§‹èŒƒå›´å’Œç±»å‹
        filtered = (filtered - filtered.min()) / (filtered.max() - filtered.min())
        filtered = filtered * (data.max() - data.min()) + data.min()
        
        return filtered.astype(np.uint16)
    
    @staticmethod
    def median_filter(data: np.ndarray, disk_size: int = 3) -> np.ndarray:
        """ä¸­å€¼æ»¤æ³¢"""
        if disk_size < 1:
            disk_size = 1
        
        # ä½¿ç”¨åœ†å½¢ç»“æ„å…ƒç´ 
        selem = morphology.disk(disk_size)
        filtered = filters.median(data, selem)
        
        return filtered.astype(np.uint16)
    
    @staticmethod
    def unsharp_mask(data: np.ndarray, radius: float = 1.0, amount: float = 1.0) -> np.ndarray:
        """éé”åŒ–æ©æ¨¡"""
        if radius <= 0:
            radius = 0.1
        if amount < 0:
            amount = 0
        
        # è½¬æ¢ä¸ºfloatç±»å‹è¿›è¡Œå¤„ç†
        data_float = data.astype(np.float32)
        
        # åº”ç”¨éé”åŒ–æ©æ¨¡
        sharpened = filters.unsharp_mask(data_float, radius=radius, amount=amount)
        
        # æ¢å¤åˆ°åŸå§‹èŒƒå›´å’Œç±»å‹ï¼ˆé¿å…é™¤é›¶é”™è¯¯ï¼‰
        sharpened_min = sharpened.min()
        sharpened_max = sharpened.max()

        if sharpened_max > sharpened_min:
            sharpened = (sharpened - sharpened_min) / (sharpened_max - sharpened_min)
            sharpened = sharpened * (data.max() - data.min()) + data.min()
        else:
            # å¦‚æœå›¾åƒæ˜¯å¸¸æ•°ï¼Œç›´æ¥è¿”å›åŸå›¾åƒ
            sharpened = data.astype(np.float64)

        return np.clip(sharpened, 0, 65535).astype(np.uint16)
    
    @staticmethod
    def morphological_operation(data: np.ndarray, operation: str, disk_size: int = 3) -> np.ndarray:
        """å½¢æ€å­¦æ“ä½œ"""
        if disk_size < 1:
            disk_size = 1
        
        # åˆ›å»ºç»“æ„å…ƒç´ 
        selem = morphology.disk(disk_size)
        
        # æ ¹æ®æ“ä½œç±»å‹å¤„ç†
        if operation == 'erosion':
            result = morphology.erosion(data, selem)
        elif operation == 'dilation':
            result = morphology.dilation(data, selem)
        elif operation == 'opening':
            result = morphology.opening(data, selem)
        elif operation == 'closing':
            result = morphology.closing(data, selem)
        else:
            result = data
        
        return result.astype(np.uint16)
    
    @staticmethod
    def low_pass_filter(data: np.ndarray, cutoff_frequency: float = 0.1) -> np.ndarray:
        """ä½é€šæ»¤æ³¢ï¼ˆé¢‘åŸŸï¼‰"""
        # è½¬æ¢ä¸ºfloatç±»å‹
        data_float = data.astype(np.float32)
        
        # å‚…é‡Œå¶å˜æ¢
        f_transform = np.fft.fft2(data_float)
        f_transform_shifted = np.fft.fftshift(f_transform)
        
        # åˆ›å»ºä½é€šæ»¤æ³¢å™¨
        rows, cols = data.shape
        crow, ccol = rows // 2, cols // 2
        
        # åˆ›å»ºé«˜æ–¯ä½é€šæ»¤æ³¢å™¨
        y, x = np.ogrid[:rows, :cols]
        mask = np.exp(-((x - ccol) ** 2 + (y - crow) ** 2) / (2 * (cutoff_frequency * min(rows, cols)) ** 2))
        
        # åº”ç”¨æ»¤æ³¢å™¨
        filtered = f_transform_shifted * mask
        
        # é€†å˜æ¢
        filtered_shifted = np.fft.ifftshift(filtered)
        filtered_result = np.fft.ifft2(filtered_shifted)
        filtered_result = np.real(filtered_result)
        
        # æ¢å¤åˆ°åŸå§‹èŒƒå›´å’Œç±»å‹
        filtered_result = (filtered_result - filtered_result.min()) / (filtered_result.max() - filtered_result.min())
        filtered_result = filtered_result * (data.max() - data.min()) + data.min()
        
        return filtered_result.astype(np.uint16)
    
    @staticmethod
    def high_pass_filter(data: np.ndarray, cutoff_frequency: float = 0.1) -> np.ndarray:
        """é«˜é€šæ»¤æ³¢ï¼ˆé¢‘åŸŸï¼‰"""
        # è½¬æ¢ä¸ºfloatç±»å‹
        data_float = data.astype(np.float32)
        
        # å‚…é‡Œå¶å˜æ¢
        f_transform = np.fft.fft2(data_float)
        f_transform_shifted = np.fft.fftshift(f_transform)
        
        # åˆ›å»ºé«˜é€šæ»¤æ³¢å™¨
        rows, cols = data.shape
        crow, ccol = rows // 2, cols // 2
        
        # åˆ›å»ºé«˜æ–¯é«˜é€šæ»¤æ³¢å™¨
        y, x = np.ogrid[:rows, :cols]
        mask = 1 - np.exp(-((x - ccol) ** 2 + (y - crow) ** 2) / (2 * (cutoff_frequency * min(rows, cols)) ** 2))
        
        # åº”ç”¨æ»¤æ³¢å™¨
        filtered = f_transform_shifted * mask
        
        # é€†å˜æ¢
        filtered_shifted = np.fft.ifftshift(filtered)
        filtered_result = np.fft.ifft2(filtered_shifted)
        filtered_result = np.real(filtered_result)
        
        # æ¢å¤åˆ°åŸå§‹èŒƒå›´å’Œç±»å‹
        filtered_result = (filtered_result - filtered_result.min()) / (filtered_result.max() - filtered_result.min())
        filtered_result = filtered_result * (data.max() - data.min()) + data.min()
        
        return filtered_result.astype(np.uint16)
    
    @staticmethod
    def get_algorithm_info() -> Dict[str, Dict[str, Any]]:
        """è·å–ç®—æ³•ä¿¡æ¯"""
        return {
            'gamma_correction': {
                'name': 'Gammaæ ¡æ­£',
                'description': 'è°ƒæ•´å›¾åƒçš„äº®åº¦åˆ†å¸ƒ',
                'parameters': {
                    'gamma': {'type': 'float', 'range': (0.1, 5.0), 'default': 1.0, 'description': 'Gammaå€¼'}
                }
            },
            'histogram_equalization': {
                'name': 'ç›´æ–¹å›¾å‡è¡¡åŒ–',
                'description': 'æ”¹å–„å›¾åƒå¯¹æ¯”åº¦',
                'parameters': {
                    'method': {'type': 'string', 'options': ['global', 'adaptive'], 'default': 'global', 'description': 'å‡è¡¡åŒ–æ–¹æ³•'}
                }
            },
            'gaussian_filter': {
                'name': 'é«˜æ–¯æ»¤æ³¢',
                'description': 'é«˜æ–¯é™å™ª',
                'parameters': {
                    'sigma': {'type': 'float', 'range': (0.1, 10.0), 'default': 1.0, 'description': 'é«˜æ–¯æ ¸æ ‡å‡†å·®'}
                }
            },
            'median_filter': {
                'name': 'ä¸­å€¼æ»¤æ³¢',
                'description': 'ä¸­å€¼é™å™ª',
                'parameters': {
                    'disk_size': {'type': 'int', 'range': (1, 10), 'default': 3, 'description': 'æ»¤æ³¢å™¨å¤§å°'}
                }
            },
            'unsharp_mask': {
                'name': 'éé”åŒ–æ©æ¨¡',
                'description': 'å›¾åƒé”åŒ–',
                'parameters': {
                    'radius': {'type': 'float', 'range': (0.1, 5.0), 'default': 1.0, 'description': 'é”åŒ–åŠå¾„'},
                    'amount': {'type': 'float', 'range': (0.0, 3.0), 'default': 1.0, 'description': 'é”åŒ–å¼ºåº¦'}
                }
            },
            'morphological_operation': {
                'name': 'å½¢æ€å­¦æ“ä½œ',
                'description': 'å½¢æ€å­¦å¤„ç†',
                'parameters': {
                    'operation': {'type': 'string', 'options': ['erosion', 'dilation', 'opening', 'closing'], 'default': 'erosion', 'description': 'æ“ä½œç±»å‹'},
                    'disk_size': {'type': 'int', 'range': (1, 10), 'default': 3, 'description': 'ç»“æ„å…ƒç´ å¤§å°'}
                }
            }
        }

    # ==================== é¢‘åŸŸå¢å¼ºæ–¹æ³• ====================

    @staticmethod
    def ideal_low_pass_filter(data: np.ndarray, cutoff_ratio: float = 0.1) -> np.ndarray:
        """ç†æƒ³ä½é€šæ»¤æ³¢"""
        return FrequencyProcessor.ideal_low_pass(data, cutoff_ratio)

    @staticmethod
    def ideal_high_pass_filter(data: np.ndarray, cutoff_ratio: float = 0.1) -> np.ndarray:
        """ç†æƒ³é«˜é€šæ»¤æ³¢"""
        return FrequencyProcessor.ideal_high_pass(data, cutoff_ratio)

    @staticmethod
    def gaussian_low_pass_filter(data: np.ndarray, cutoff_ratio: float = 0.1) -> np.ndarray:
        """é«˜æ–¯ä½é€šæ»¤æ³¢"""
        return FrequencyProcessor.gaussian_low_pass(data, cutoff_ratio)

    @staticmethod
    def gaussian_high_pass_filter(data: np.ndarray, cutoff_ratio: float = 0.1) -> np.ndarray:
        """é«˜æ–¯é«˜é€šæ»¤æ³¢"""
        return FrequencyProcessor.gaussian_high_pass(data, cutoff_ratio)

    # ==================== è¾¹ç¼˜æ£€æµ‹æ–¹æ³• ====================

    @staticmethod
    def sobel_edge_detection(data: np.ndarray) -> np.ndarray:
        """Sobelè¾¹ç¼˜æ£€æµ‹"""
        return EdgeProcessor.sobel_edge(data)

    @staticmethod
    def canny_edge_detection(data: np.ndarray, sigma: float = 1.0,
                           low_threshold: float = 0.1, high_threshold: float = 0.2) -> np.ndarray:
        """Cannyè¾¹ç¼˜æ£€æµ‹"""
        return EdgeProcessor.canny_edge(data, sigma, low_threshold, high_threshold)

    @staticmethod
    def laplacian_edge_detection(data: np.ndarray) -> np.ndarray:
        """Laplacianè¾¹ç¼˜æ£€æµ‹"""
        return EdgeProcessor.laplacian_edge(data)

    @staticmethod
    def edge_enhancement(data: np.ndarray, edge_strength: float = 1.0,
                        edge_method: str = 'sobel') -> np.ndarray:
        """è¾¹ç¼˜å¢å¼º"""
        return EdgeProcessor.edge_enhancement(data, edge_strength, edge_method)

    @staticmethod
    def roberts_edge_detection(data: np.ndarray) -> np.ndarray:
        """Robertsè¾¹ç¼˜æ£€æµ‹"""
        return EdgeProcessor.roberts_edge(data)

    # ==================== DICOMå¢å¼ºæ–¹æ³• ====================

    @staticmethod
    def dicom_basic_enhance(data: np.ndarray) -> np.ndarray:
        """DICOMæ™®é€šå¢å¼º"""
        return DicomEnhancer.basic_enhance(data)

    @staticmethod
    def dicom_advanced_enhance(data: np.ndarray) -> np.ndarray:
        """DICOMé«˜çº§å¢å¼º"""
        return DicomEnhancer.advanced_enhance(data)

    @staticmethod
    def dicom_super_enhance(data: np.ndarray) -> np.ndarray:
        """DICOMè¶…çº§å¢å¼º"""
        return DicomEnhancer.super_enhance(data)

    @staticmethod
    def dicom_auto_enhance(data: np.ndarray) -> np.ndarray:
        """DICOMä¸€é”®å¤„ç†"""
        return DicomEnhancer.auto_enhance(data)

    @staticmethod
    def window_based_enhance(data: np.ndarray, window_width: float, window_level: float) -> np.ndarray:
        """åŸºäºçª—å®½çª—ä½çš„ç¼ºé™·æ£€æµ‹å¢å¼º"""
        return WindowBasedEnhancer.window_based_enhance(data, window_width, window_level)

    @staticmethod
    def paper_enhance(data: np.ndarray, progress_callback=None) -> np.ndarray:
        """è®ºæ–‡ç®—æ³•ï¼šåŸºäºæ¢¯åº¦åœºå’Œéå±€éƒ¨å‡å€¼çš„å¤æ‚å·¥ä»¶å›¾åƒå¢å¼ºç®—æ³•"""
        print(f"\nğŸ“„ è®ºæ–‡ç®—æ³•å¤„ç†:")
        print(f"   è¾“å…¥æ•°æ®èŒƒå›´: {data.min()} - {data.max()}")
        print(f"   è¾“å…¥æ•°æ®ç±»å‹: {data.dtype}")
        print(f"   å›¾åƒå¤§å°: {data.shape}")

        if progress_callback:
            progress_callback(0.1)

        try:
            print(f"   ğŸ”„ å¼€å§‹æ‰§è¡Œè®ºæ–‡ç®—æ³•ï¼ˆé¢„è®¡éœ€è¦10-30ç§’ï¼‰...")

            if progress_callback:
                progress_callback(0.2)

            print(f"   ğŸ“Š Step1: å¼€å§‹æ¢¯åº¦åœºè‡ªé€‚åº”å¢å¼º...")

            # ä¸ºäº†è°ƒè¯•ï¼Œæˆ‘ä»¬å…ˆå°è¯•æ›´å¿«çš„å‚æ•°
            print(f"   ğŸ”§ ä½¿ç”¨åŠ é€Ÿå‚æ•°è¿›è¡Œæµ‹è¯•...")

            # è°ƒç”¨è®ºæ–‡ç®—æ³•ï¼ˆä½¿ç”¨æ–°çš„ä¼˜åŒ–æ¥å£ï¼‰
            def progress_wrapper(progress):
                if progress_callback:
                    progress_callback(progress)

            I_enh, (Gx_p, Gy_p), (Gx, Gy), nctx = enhance_xray_poisson_nlm_strict(
                data,
                # å½’ä¸€åŒ–å‚æ•°
                norm_mode="percentile", p_lo=0.5, p_hi=99.5,
                # Step1: æ¢¯åº¦åœºå¢å¼ºå‚æ•°
                epsilon_8bit=2.3, mu=10.0, ksize_var=5,
                # Step2: NLMå‚æ•°ï¼ˆå¿«é€Ÿæ¨¡å¼ä¼šè‡ªåŠ¨æ˜ å°„ï¼‰
                rho=1.5, search_radius=3, patch_radius=2, topk=15,
                count_target_mean=18.0,  # 0.3 * 60.0ï¼Œå¯¹åº”åŸæ¥çš„count_scale=0.3
                lam_quant=0.02,
                # Step3: å˜åˆ†é‡å»ºå‚æ•°
                gamma=0.2, delta=0.8, iters=5, dt=0.15,
                # è¾“å‡ºå‚æ•°
                out_dtype=np.uint16,
                # è¿›åº¦å›è°ƒ
                progress_callback=progress_wrapper,
                # å¿«é€Ÿæ¨¡å¼ï¼ˆè‡ªåŠ¨åˆ¤æ–­ï¼‰
                use_fast_nlm=None  # None=è‡ªåŠ¨åˆ¤æ–­ï¼Œå¤§å›¾åƒä¼šè‡ªåŠ¨ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
            )

            print(f"   ğŸ“Š è®ºæ–‡ç®—æ³•æ ¸å¿ƒå¤„ç†å®Œæˆï¼Œå¼€å§‹åå¤„ç†...")

            if progress_callback:
                progress_callback(0.9)

            print(f"   è¾“å‡ºæ•°æ®èŒƒå›´: {I_enh.min()} - {I_enh.max()}")
            print(f"   è¾“å‡ºæ•°æ®ç±»å‹: {I_enh.dtype}")
            print(f"   æ¢¯åº¦åœºèŒƒå›´: Gx_p[{Gx_p.min():.2f}, {Gx_p.max():.2f}], Gy_p[{Gy_p.min():.2f}, {Gy_p.max():.2f}]")
            print(f"   å¤„ç†åæ¢¯åº¦: Gx[{Gx.min():.2f}, {Gx.max():.2f}], Gy[{Gy.min():.2f}, {Gy.max():.2f}]")
            print(f"   å½’ä¸€åŒ–ä¸Šä¸‹æ–‡: vmin={nctx['vmin']:.1f}, vmax={nctx['vmax']:.1f}")

            # æ–°å‡½æ•°ç›´æ¥è¿”å›16ä½ç»“æœï¼Œæ— éœ€è½¬æ¢
            result = I_enh

            if progress_callback:
                progress_callback(1.0)

            print(f"   âœ… è®ºæ–‡ç®—æ³•å¤„ç†å®Œæˆ")
            return result

        except Exception as e:
            print(f"   âŒ è®ºæ–‡ç®—æ³•å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # è¿”å›åŸå§‹æ•°æ®
            return data