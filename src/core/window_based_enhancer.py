"""
åŸºäºçª—å®½çª—ä½çš„DICOMå›¾åƒå¢å¼ºå¤„ç†å™¨
ä¸“é—¨ç”¨äºçªå‡ºç»†å°ç¼ºé™·çš„å›¾åƒå¢å¼ºç®—æ³•
"""
import numpy as np
import cv2
from typing import Optional, Callable


class WindowBasedEnhancer:
    """åŸºäºçª—å®½çª—ä½çš„DICOMå›¾åƒå¢å¼ºå¤„ç†å™¨"""

    @staticmethod
    def _detect_effective_range(data: np.ndarray) -> tuple:
        """æ£€æµ‹æœ‰æ•ˆæ•°æ®èŒƒå›´ï¼ˆå¤ç”¨è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•çš„é€»è¾‘ï¼‰

        Args:
            data: å›¾åƒæ•°æ®

        Returns:
            tuple: (effective_min, effective_max)
        """
        data_min = int(data.min())
        data_max = int(data.max())
        total_pixels = data.size

        # è®¡ç®—ç›´æ–¹å›¾
        hist, bins = np.histogram(data.flatten(), bins=65536, range=(data_min, data_max))
        bin_centers = 0.5 * (bins[:-1] + bins[1:])

        # æ£€æµ‹è¿‡æ›å³°å€¼ï¼ˆä¸è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•ç›¸åŒçš„é€»è¾‘ï¼‰
        pixel_ratios = hist / total_pixels
        major_peaks = np.where(pixel_ratios > 0.05)[0]  # è¶…è¿‡5%çš„bins

        overexposed_peaks = []
        for peak_idx in major_peaks:
            peak_value = bin_centers[peak_idx]
            peak_ratio = pixel_ratios[peak_idx]
            # è¿‡æ›åˆ¤æ–­ï¼šç°åº¦å€¼ > 80%èŒƒå›´ ä¸” åƒç´ æ•° > 5%
            if peak_value > (data_min + (data_max - data_min) * 0.8):
                overexposed_peaks.append((peak_value, peak_ratio))

        if overexposed_peaks:
            # æ£€æµ‹åˆ°è¿‡æ›èƒŒæ™¯ï¼Œä½¿ç”¨å·¥ä»¶æ£€æµ‹ç®—æ³•
            overexposed_threshold = min(peak[0] for peak in overexposed_peaks)
            noise_threshold = total_pixels * 0.0001

            # æ‰¾åˆ°æœ‰æ•ˆçš„å·¥ä»¶æ•°æ®åŒºåŸŸ
            valid_bins = np.where((bin_centers < overexposed_threshold) & (hist > noise_threshold))[0]

            if len(valid_bins) > 10:
                # åœ¨æœ‰æ•ˆåŒºåŸŸå†…è®¡ç®—5%-95%
                valid_pixels = np.sum(hist[valid_bins])
                valid_cumulative = np.cumsum(hist[valid_bins])

                lower_threshold = valid_pixels * 0.05
                upper_threshold = valid_pixels * 0.95

                lower_idx = np.where(valid_cumulative >= lower_threshold)[0]
                upper_idx = np.where(valid_cumulative >= upper_threshold)[0]

                if len(lower_idx) > 0 and len(upper_idx) > 0:
                    effective_min = bin_centers[valid_bins[lower_idx[0]]]
                    effective_max = bin_centers[valid_bins[upper_idx[0]]]
                    return effective_min, effective_max

        # å›é€€ï¼šä½¿ç”¨æ ‡å‡†5%-95%ç®—æ³•
        cumulative_pixels = np.cumsum(hist)
        lower_bound = np.where(cumulative_pixels >= total_pixels * 0.05)[0]
        upper_bound = np.where(cumulative_pixels >= total_pixels * 0.95)[0]

        if len(lower_bound) > 0 and len(upper_bound) > 0:
            effective_min = bin_centers[lower_bound[0]]
            effective_max = bin_centers[upper_bound[0]]
        else:
            # æœ€ç»ˆå›é€€
            effective_min = float(data_min)
            effective_max = float(data_max)

        return effective_min, effective_max
    
    @staticmethod
    def window_based_enhance(data: np.ndarray, window_width: float, window_level: float, 
                           progress_callback: Optional[Callable] = None) -> np.ndarray:
        """
        åŸºäºçª—å®½çª—ä½çš„ç¼ºé™·æ£€æµ‹å¢å¼ºç®—æ³•
        
        Args:
            data: è¾“å…¥å›¾åƒæ•°æ®ï¼ˆ16ä½DICOMåŸå§‹æ•°æ®ï¼‰
            window_width: çª—å®½
            window_level: çª—ä½
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¢å¼ºåçš„å›¾åƒæ•°æ®
        """
        try:
            if progress_callback:
                progress_callback(5)

            print(f"\nğŸ” çª—ä½å¢å¼ºDebugæ—¥å¿—:")
            print(f"   è¾“å…¥æ•°æ®èŒƒå›´: {data.min()} - {data.max()}")
            print(f"   è¾“å…¥æ•°æ®å‡å€¼: {data.mean():.2f}")
            print(f"   è¾“å…¥æ•°æ®æ ‡å‡†å·®: {data.std():.2f}")
            print(f"   çª—å®½: {window_width}, çª—ä½: {window_level}")
            print(f"   ğŸ”§ ä½¿ç”¨å…¨èŒƒå›´å¤„ç†ç­–ç•¥ï¼ˆé¿å…åŠ¨æ€èŒƒå›´å‹ç¼©ï¼‰")

            # 1. æ£€æµ‹æ„Ÿå…´è¶£åŒºåŸŸï¼ˆç”¨äºè‡ªé€‚åº”å¤„ç†ï¼Œä½†ä¸è£å‰ªæ•°æ®ï¼‰
            wl_min = window_level - window_width / 2
            wl_max = window_level + window_width / 2
            roi_mask = (data >= wl_min) & (data <= wl_max)
            roi_ratio = np.sum(roi_mask) / data.size

            print(f"   æ„Ÿå…´è¶£åŒºåŸŸ: {wl_min} - {wl_max}")
            print(f"   æ„Ÿå…´è¶£åƒç´ æ¯”ä¾‹: {roi_ratio*100:.1f}%")

            if progress_callback:
                progress_callback(15)

            # 2. å…¨èŒƒå›´å½’ä¸€åŒ–ï¼ˆä¿æŒå®Œæ•´åŠ¨æ€èŒƒå›´ï¼‰
            data_min = float(data.min())
            data_max = float(data.max())
            img_norm = (data.astype(np.float32) - data_min) / (data_max - data_min)

            print(f"   å…¨èŒƒå›´å½’ä¸€åŒ–: {data_min} - {data_max}")
            print(f"   å½’ä¸€åŒ–åèŒƒå›´: {img_norm.min():.4f} - {img_norm.max():.4f}")
            print(f"   å½’ä¸€åŒ–åå‡å€¼: {img_norm.mean():.4f}")
            print(f"   å½’ä¸€åŒ–åæ ‡å‡†å·®: {img_norm.std():.4f}")

            # 3. åˆ›å»ºæ„Ÿå…´è¶£åŒºåŸŸçš„æƒé‡å›¾ï¼ˆç”¨äºè‡ªé€‚åº”å¢å¼ºï¼‰
            roi_weight = np.zeros_like(img_norm)
            roi_weight[roi_mask] = 1.0
            # å¯¹æƒé‡å›¾è¿›è¡Œé«˜æ–¯æ¨¡ç³Šï¼Œåˆ›å»ºå¹³æ»‘è¿‡æ¸¡
            roi_weight = cv2.GaussianBlur(roi_weight, (21, 21), 7)

            print(f"   æ„Ÿå…´è¶£åŒºåŸŸæƒé‡èŒƒå›´: {roi_weight.min():.4f} - {roi_weight.max():.4f}")

            if progress_callback:
                progress_callback(25)

            # 4. å™ªå£°æ£€æµ‹ï¼ˆåœ¨æ„Ÿå…´è¶£åŒºåŸŸå†…ï¼‰
            var_map = cv2.GaussianBlur(img_norm**2, (7, 7), 0) - cv2.GaussianBlur(img_norm, (7, 7), 0)**2
            var_map = np.clip(var_map / (var_map.max() + 1e-8), 0, 1)

            # åœ¨æ„Ÿå…´è¶£åŒºåŸŸå†…è®¡ç®—å™ªå£°ç»Ÿè®¡
            roi_var = var_map[roi_mask]
            noise_level = np.mean(roi_var) if len(roi_var) > 0 else np.mean(var_map)
            high_noise_ratio = np.sum(roi_var > 0.5) / len(roi_var) if len(roi_var) > 0 else 0

            print(f"   æ„Ÿå…´è¶£åŒºåŸŸå™ªå£°æ°´å¹³: {noise_level:.4f}")
            print(f"   æ„Ÿå…´è¶£åŒºåŸŸé«˜å™ªå£°æ¯”ä¾‹: {high_noise_ratio*100:.1f}%")

            # 5. è‡ªé€‚åº”å¤šå°ºåº¦é«˜é¢‘å¢å¼º
            blur_small = cv2.GaussianBlur(img_norm, (0, 0), 1)
            high_freq_small = img_norm - blur_small
            blur_large = cv2.GaussianBlur(img_norm, (0, 0), 5)
            high_freq_large = img_norm - blur_large

            print(f"   å°å°ºåº¦é«˜é¢‘èŒƒå›´: {high_freq_small.min():.4f} - {high_freq_small.max():.4f}")
            print(f"   å¤§å°ºåº¦é«˜é¢‘èŒƒå›´: {high_freq_large.min():.4f} - {high_freq_large.max():.4f}")

            # æ ¹æ®å™ªå£°æ°´å¹³è°ƒæ•´å¢å¼ºå¼ºåº¦
            if noise_level > 0.1:
                base_strength_small, base_strength_large = 0.8, 0.4
                print(f"   ğŸ”§ æ£€æµ‹åˆ°é«˜å™ªå£°ï¼Œä½¿ç”¨ä¿å®ˆå¢å¼º")
            elif noise_level > 0.05:
                base_strength_small, base_strength_large = 1.2, 0.6
                print(f"   ğŸ”§ æ£€æµ‹åˆ°ä¸­ç­‰å™ªå£°ï¼Œä½¿ç”¨ä¸­ç­‰å¢å¼º")
            else:
                base_strength_small, base_strength_large = 1.5, 0.8
                print(f"   ğŸ”§ æ£€æµ‹åˆ°ä½å™ªå£°ï¼Œä½¿ç”¨æ­£å¸¸å¢å¼º")

            # ä½¿ç”¨æƒé‡å›¾è¿›è¡Œç©ºé—´è‡ªé€‚åº”å¢å¼º
            # æ„Ÿå…´è¶£åŒºåŸŸå†…ï¼šä½¿ç”¨è®¾å®šçš„å¢å¼ºå¼ºåº¦
            # æ„Ÿå…´è¶£åŒºåŸŸå¤–ï¼šä½¿ç”¨è¾ƒå¼±çš„å¢å¼ºå¼ºåº¦
            strength_small = base_strength_small * roi_weight + 0.3 * (1 - roi_weight)
            strength_large = base_strength_large * roi_weight + 0.2 * (1 - roi_weight)

            print(f"   ç©ºé—´è‡ªé€‚åº”å¢å¼º: ROIå†…={base_strength_small:.1f}/{base_strength_large:.1f}, ROIå¤–=0.3/0.2")

            # åº”ç”¨ç©ºé—´è‡ªé€‚åº”å¢å¼º
            img_detail = img_norm + strength_small * high_freq_small + strength_large * high_freq_large
            img_detail = np.clip(img_detail, 0, 1)

            print(f"   å¢å¼ºåèŒƒå›´: {img_detail.min():.4f} - {img_detail.max():.4f}")
            print(f"   å¢å¼ºåå‡å€¼: {img_detail.mean():.4f}")

            if progress_callback:
                progress_callback(45)

            # 5. å®‰å…¨çš„å…‰ç…§å½’ä¸€åŒ–ï¼ˆé˜²æ­¢æ•°å€¼çˆ†ç‚¸ï¼‰
            illum = cv2.GaussianBlur(img_detail, (0, 0), 50)

            print(f"   å…‰ç…§å½’ä¸€åŒ–å‰: {img_detail.min():.4f} - {img_detail.max():.4f}")
            print(f"   å…‰ç…§å›¾èŒƒå›´: {illum.min():.4f} - {illum.max():.4f}")

            # å®‰å…¨çš„å…‰ç…§å½’ä¸€åŒ–ï¼šé™åˆ¶é™¤æ³•ç»“æœ
            illum_safe = np.clip(illum, 0.1, 1.0)  # é˜²æ­¢é™¤ä»¥è¿‡å°çš„æ•°
            img_light_norm = img_detail / illum_safe
            img_light_norm = np.clip(img_light_norm, 0, 2.0)  # é™åˆ¶æœ€å¤§å€¼ä¸º2å€

            print(f"   å®‰å…¨å…‰ç…§å½’ä¸€åŒ–å: {img_light_norm.min():.4f} - {img_light_norm.max():.4f}")

            # å¼±åŒ–å…‰ç…§å½’ä¸€åŒ–æ•ˆæœï¼Œä¸»è¦ä¿ç•™åŸå›¾
            img_light_norm = 0.3 * img_light_norm + 0.7 * img_detail  # é™ä½å…‰ç…§å½’ä¸€åŒ–æƒé‡
            img_light_norm = np.clip(img_light_norm, 0, 1)

            print(f"   æ··åˆåèŒƒå›´: {img_light_norm.min():.4f} - {img_light_norm.max():.4f}")

            if progress_callback:
                progress_callback(65)

            # 6. Gammaæ›²çº¿è°ƒæ•´ï¼ˆæ ¹æ®å™ªå£°æ°´å¹³è°ƒæ•´ï¼‰
            if noise_level > 0.1:
                gamma = 0.9  # é«˜å™ªå£°ï¼šä¿å®ˆçš„gamma
            else:
                gamma = 0.8  # ä½å™ªå£°ï¼šæ­£å¸¸gamma

            print(f"   Gammaå€¼: {gamma}")
            img_gamma = np.power(img_light_norm, gamma)
            print(f"   Gammaè°ƒæ•´å: {img_gamma.min():.4f} - {img_gamma.max():.4f}")

            if progress_callback:
                progress_callback(80)

            # 7. æ¸©å’Œçš„CLAHEå¢å¼ºï¼ˆé¿å…è¿‡åº¦æ‹‰ä¼¸ï¼‰
            img_16bit = (img_gamma * 65535).astype(np.uint16)

            if noise_level > 0.1:
                # é«˜å™ªå£°ï¼šéå¸¸æ¸©å’Œçš„CLAHE
                clip_limit = 1.2
                tile_size = (16, 16)
                print(f"   ğŸ”§ é«˜å™ªå£°æ¨¡å¼ï¼šæ¸©å’ŒCLAHE clipLimit={clip_limit}, tileSize={tile_size}")
            else:
                # ä½å™ªå£°ï¼šæ¸©å’ŒCLAHE
                clip_limit = 1.5
                tile_size = (8, 8)
                print(f"   ğŸ”§ æ­£å¸¸æ¨¡å¼ï¼šæ¸©å’ŒCLAHE clipLimit={clip_limit}, tileSize={tile_size}")

            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)
            img_clahe = clahe.apply(img_16bit)

            print(f"   CLAHEåèŒƒå›´: {img_clahe.min()} - {img_clahe.max()}")

            if progress_callback:
                progress_callback(95)

            # 8. è¾“å‡ºå…¨èŒƒå›´æ•°æ®ï¼ˆæ˜ å°„å›åŸå§‹æ•°æ®èŒƒå›´ï¼‰
            clahe_min = float(img_clahe.min())
            clahe_max = float(img_clahe.max())

            # æ˜ å°„å›åŸå§‹æ•°æ®çš„å…¨èŒƒå›´
            result_float = (img_clahe.astype(np.float32) - clahe_min) / (clahe_max - clahe_min)
            result_float = result_float * (data_max - data_min) + data_min

            print(f"   CLAHEèŒƒå›´: {clahe_min:.0f} - {clahe_max:.0f}")
            print(f"   æ˜ å°„å›å…¨èŒƒå›´: {data_min:.0f} - {data_max:.0f}")

            # 9. è½»å¾®æ··åˆåŸå›¾ï¼ˆä¿ç•™è´¨æ„Ÿå’Œå…¨èŒƒå›´ï¼‰
            alpha = 0.85  # å¢å¼ºç»“æœæƒé‡
            result = cv2.addWeighted(result_float, alpha, data.astype(np.float32), 1 - alpha, 0)
            result = np.clip(result, data_min, data_max).astype(np.uint16)

            print(f"   æ··åˆåèŒƒå›´: {result.min()} - {result.max()}")

            print(f"   æœ€ç»ˆè¾“å‡ºèŒƒå›´: {result.min()} - {result.max()}")
            print(f"   æœ€ç»ˆè¾“å‡ºå‡å€¼: {result.mean():.2f}")
            print(f"   æœ€ç»ˆè¾“å‡ºæ ‡å‡†å·®: {result.std():.2f}")
            print(f"   âœ… çª—ä½å¢å¼ºå®Œæˆ\n")

            if progress_callback:
                progress_callback(100)

            return result
            
        except Exception as e:
            raise RuntimeError(f"åŸºäºçª—å®½çª—ä½çš„å¢å¼ºå¤„ç†å¤±è´¥: {str(e)}")
    
    @staticmethod
    def get_algorithm_info() -> dict:
        """è·å–ç®—æ³•ä¿¡æ¯"""
        return {
            'name': 'åŸºäºçª—å®½çª—ä½çš„å¹³è¡¡å¢å¼º',
            'version': '2.0',
            'description': 'å¹³è¡¡ç‰ˆç¼ºé™·æ£€æµ‹å¢å¼ºç®—æ³•ï¼Œè§†è§‰æ•ˆæœæ›´ä½³',
            'features': [
                'åŸºäºçª—å®½çª—ä½çš„æ•°æ®ç­›é€‰',
                'å¹³è¡¡çš„å¤šå°ºåº¦é«˜é¢‘å¢å¼º',
                'å¼±åŒ–å…‰ç…§å½’ä¸€åŒ–ï¼ˆé˜²æ­¢è¿‡äº®ï¼‰',
                'Gammaæ›²çº¿è°ƒæ•´ï¼ˆå‹äº®ææš—ï¼‰',
                'CLAHEå¯¹æ¯”åº¦å¢å¼º',
                'åŸå›¾æ··åˆï¼ˆä¿ç•™è´¨æ„Ÿï¼‰'
            ],
            'advantages': [
                'åªå¤„ç†ç”¨æˆ·å…³å¿ƒçš„ç°åº¦èŒƒå›´',
                'é¿å…èƒŒæ™¯å™ªå£°å¹²æ‰°',
                'å¹³è¡¡çš„å¢å¼ºæ•ˆæœï¼Œä¸è¿‡åº¦å¤„ç†',
                'ä¿ç•™åŸå§‹å›¾åƒè´¨æ„Ÿ',
                'æ›´å¥½çš„è§†è§‰æ•ˆæœ'
            ],
            'improvements': [
                'ç®€åŒ–é«˜é¢‘å¢å¼ºï¼ˆå›ºå®šå¼ºåº¦ï¼‰',
                'å¼±åŒ–å…‰ç…§å½’ä¸€åŒ–æ•ˆæœ',
                'æ–°å¢Gammaæ›²çº¿è°ƒæ•´',
                'æ–°å¢åŸå›¾æ··åˆä¿è´¨æ„Ÿ'
            ]
        }
    
    @staticmethod
    def _debug_info(data: np.ndarray, window_width: float, window_level: float) -> dict:
        """è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰"""
        wl_min = window_level - window_width / 2
        wl_max = window_level + window_width / 2
        
        # ç»Ÿè®¡åŸå§‹æ•°æ®
        original_min = float(data.min())
        original_max = float(data.max())
        original_mean = float(data.mean())
        
        # ç»Ÿè®¡çª—å®½çª—ä½åçš„æ•°æ®
        windowed_data = np.clip(data, wl_min, wl_max)
        windowed_pixels = np.sum((data >= wl_min) & (data <= wl_max))
        total_pixels = data.size
        effective_ratio = windowed_pixels / total_pixels
        
        return {
            'original_range': (original_min, original_max),
            'original_mean': original_mean,
            'window_range': (wl_min, wl_max),
            'effective_pixels_ratio': effective_ratio,
            'total_pixels': total_pixels,
            'effective_pixels': windowed_pixels
        }
